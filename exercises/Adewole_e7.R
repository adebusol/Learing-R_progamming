#Exercise 7: merging data sets & practicing working with data sets

# GOAL: Your goal is to merge the 'starec', 'envrec' and 'aurelia' data so you can visualize how jellyfish biomass varies with oxygen concentrations.

#load libraries----
library(tidyverse)
library(stringr)

#functions -----
clean.quotes <- function(y){
  gsub(pattern = '"', replacement = "", x = y)
}
clean.whitespace<- function(y){
  gsub(pattern = ' ', replacement = "", x = y)
}

'%!in%' <- function(x,y)!('%in%'(x,y)) #custom operator to find columns that are not in a data frame
#-----

# 1) Import the "STAREC_rev20190402.csv" file. You will need to use the following arguments:
## quote="", sep = ",", check.names=T, header = T, stringsAsFactors = F, fill=T
star <-read.csv(file = "e7_seamap_data/STAREC_rev20190402.csv", sep = ",", quote = "", check.names = T, header= T, stringsAsFactors = F, fill=T)

# 2) clean up column headers
# a) remove the 'X.' from the column headers and make the names lowercase
head.star <- names(star)
head.star <- str_replace(string = head.star, pattern = "X.", replacement = "")
head.star <- make.names(head.star)
names(star) <- head.star
head.star <- tolower(head.star)
names(star)<- head.star
star
#run this to finish the clean-up
names(star) <- gsub("\\.", "", names(star))


#3) use the 'sapply' function to clean up the data.
## link to examples
browseURL("https://www.guru99.com/r-apply-sapply-tapply.html#:~:text=vertigo%22%20%22chinatown%22-,sapply()%20function,function%20but%20returns%20a%20vector.")

# a) clean quotes off of data using the 'clean.quotes' function
star <- as.data.frame(sapply(star, FUN = clean.quotes))
# b) 'clean.whitespace' off of the values in the 'gears' column
star$gears <- sapply(star$gears, FUN = clean.whitespace)


#4) convert columns that store numbers but are character into numeric data type
## workflow: extract columns that are suppose to be characters, convert the other columns to numbers

# a) extract the following character columns from the data frame
char_cols <-  star[ c("s_sta_no","time_emil","mo_day_yr","start_date","end_date","s_lath","s_lonh","e_lath",
                "e_lonh","gears","haulvalue","data_code","dbtype", "x")]

# b) create an vector object that contains the names of those character columns
str(star)
names_char_cols <- names(char_cols)

# Run lines 57-58 to identify the columns that are suppose to be numbers from 'starec' data frame.

# In other words, we are going to subset the vector generated by 'names(s)' to find the values NOT found in the vector 'names_char_cols'
# on lines 45-47

#Lines 58-59 does the exact same thing as the code in line 61; the difference is that for line 59 I
## did not bother creating a separate object for names of the two data frames
names_starec <- names(star)
to.num.cols <- names_starec[which(names_starec %!in% names_char_cols)]

to.num.cols <- names(star)[which(names(star) %!in% names(char_cols))]

# Use the 'lapply' function to go through the data frame that need to be numbers and apply the 'as.numeric' function
star[to.num.cols] <- lapply(X = star[to.num.cols], FUN = as.numeric) #there will be warnings of NAs; this is okay

#check your work; are the data frame's data types numeric?
str(star)
#yes they are

# 5) There are three columns with date-time information in the 'starec' data frame: start_date, end_date & mo_day_yr.
#convert the data type of these columns to a object that has a 'date time' class
 
datetime <- function(x){
  as.POSIXct(strptime(x, format = "%Y-%m-%d %H:%M:%OS", tz="America/New_York"))
}

star[c("start_date", "end_date")] <-lapply(X = star[c("start_date", "end_date")], FUN = datetime)
 
star$mo_day_yr<- as.POSIXct(strptime(x=star$mo_day_yr, format= "%Y-%m-%d"
                                  ))
str(star)

# 6) read in the 'envrec.csv' file ----
en <- read.csv(file = "e7_seamap_data/ENVREC.csv",sep = ",", check.names = T, header= T, stringsAsFactors = F)

# 7) keep only columns 1:31 and make all the column names be lower-case
en.new <- en[1:31]
head(en.new)
head.en.new <- names(en.new)
head.en.new <- tolower(head.en.new)
names(en.new)<- head.en.new 
en.new

# 8) merge the 'starec' and 'envrec' data frames using common column names 'stationid', 'cruiseid', 'cruise_no', and 'vessel'.
# Be mindful that the data frames have a different number of rows.

f.merge <- merge(x= star, y=en.new, by=c("stationid", "cruiseid", "cruise_no","vessel"), all = T)

# 9) there are quite a few columns here that are not germane (e.g., stat_zone) to our overall goal. Subset the merged data frame to
#keep the following columns:

names(f.merge[,c(1:4,13:31,43,53:57,73)])  #'df' refers to the object name assigned to the merged data frame created in Question #8.

newmerge <- f.merge[,c(1:4,13:31,43,53:57,73)]

# 10) reorder the columns so that the 'mo_day_yr' is the first column in the data frame

newmerge <- newmerge[c(8, 1:7,9:30)]
# 11) load the Aurelia data set
load("e7_seamap_data/aurelia_15minCell_statareas.Rdata")

# 12) filter the 'Aurelia' data set to keep the following columns
col2keep <- names(a)[c(5:16,18)]
new.a <- a[c(5:16,18)]

# 13) Take a look at the columns in the merged 'starec+envrec' data frame and the 'Aurelia' (i.e., 'a') data frame.
## What column names do you think are likely to be a 'key' between them. In other words,
## which column is common between them that could be used to merge observations correctly?
 #station.id


#14) using the 'merge' function, combine the 'aurelia' and starec+envrec data sets. Be mindful that
# the data sets have a different number of rows.
ase.merge <- merge(x= new.a, y=newmerge, by=("stationid"), all = T)

#15) repeat combining the data frames using the followwing functions from the 'join' family. In a comment, tell me how the outcomes differ?
#Here is a good reference if you need some definitions:
browseURL("https://dplyr.tidyverse.org/reference/join.html")

#a) inner_join() - this returned all the rows in x that were the same in y and also all the columns of x and y
inj<- inner_join(x = new.a, y=newmerge, by=("stationid"))

#b) left_join()  - this returned all the rows in x and also all the columns from x and y
lej <-left_join (x = new.a, y=newmerge, by=("stationid"))

#c) semi_join() this only returns all the rows in x that matches up with the rows of y, and it kept only the columns in x
sej <- semi_join(x = new.a, y=newmerge, by=("stationid"))

#16) calculate the annual mean jellyfish biomass and minimum oxygen concentration at depth (oxymax) along the 'Lou'isiana shelf
#Hints: (1) consider subsetting the columns of interest before summarizing the data; (2) you may need to detach the plyr package;
# (3) you may need to omit NA values before finding the mean statistics


col_interest <- c("year","subregion_alongshore","subregion_depth",'use_biomass_den_kg_m2',"oxymax")
finalwork<- ase.merge[c("year","subregion_alongshore","subregion_depth",'use_biomass_den_kg_m2',"oxymax")]
finalwork
finalwork <- na.omit(finalwork)
library("plyr")
detach("package:plyr")
sum.stats <- finalwork %>% group_by(year) %>% summarise(mean.bm = mean(use_biomass_den_kg_m2), mean.om = mean(oxymax), .groups= 'keep')



#plot the result ----

#data = df is a placeholder for data frame object created when you summarised by year
p <- ggplot(data = sum.stats) +
  #x = year; y=1st variable to plot on the y-axis
  geom_line(aes(x = year, y = mean.bm*100), color='firebrick', size=1) +
  #x = year; y=2nd variable to plot on the y-axis
  geom_line(aes(x = year, y = mean.om-3.5), color='steelblue4', size = 1) +
  #code to adjust the x-axis
  scale_x_continuous(name = "year",breaks = seq(from = 1982, 2018, 2)) +
  #code to adjust the y-axis
  scale_y_continuous(name = "jelly fish biomass change with oxy con", breaks = seq(0,3,0.25), expand = c(0,0)) +
  #make the plot aesthetics clean & simple
  theme_classic()
p

